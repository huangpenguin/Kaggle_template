{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./data\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/kaggle_house_pred_train.csv')\n",
    "test = pd.read_csv('./data/kaggle_house_pred_test.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantitative = [f for f in train.columns if train.dtypes[f] != 'object']\n",
    "quantitative.remove('SalePrice')\n",
    "quantitative.remove('Id')\n",
    "qualitative = [f for f in train.columns if train.dtypes[f] == 'object']\n",
    "\n",
    "# quantitative\n",
    "# qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_value\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "missing = train.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['SalePrice']\n",
    "plt.figure(1); plt.title('Johnson SU')\n",
    "sns.distplot(y, kde=False, fit=stats.johnsonsu)\n",
    "plt.figure(2); plt.title('Normal')\n",
    "sns.distplot(y, kde=False, fit=stats.norm)\n",
    "plt.figure(3); plt.title('Log Normal')\n",
    "sns.distplot(y, kde=False, fit=stats.lognorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normality = lambda x: stats.shapiro(x.fillna(0))[1] < 0.01\n",
    "normal = pd.DataFrame(train[quantitative])\n",
    "normal = normal.apply(test_normality)\n",
    "print(not normal.any())\n",
    "\n",
    "#none of quantitative variables has normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding （有序编码）\n",
    "#原理：按照类别与目标变量（SalePrice）的关系，将类别特征排序，并将每个类别分配一个数值。\n",
    "#效果：保留了类别的顺序和大小关系。编码后的值有意义，比如类别 A 对 SalePrice 的影响大于 B，编码值 A 可能比 B 大。\n",
    "\n",
    "# 和One-Hot Encoding的区别\n",
    "#One-Hot Encoding 适用于类别之间没有明显顺序或大小关系的情况（例如，颜色、城市名等）。\n",
    "#Ordinal Encoding 适用于类别与目标变量之间有明确的相关性或顺序的情况（例如评级、教育水平等）。\n",
    "\n",
    "def encode(frame, feature):\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique()\n",
    "    ordering.index = ordering.val\n",
    "    ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n",
    "    ordering = ordering.sort_values('spmean')\n",
    "    ordering['ordering'] = range(1, ordering.shape[0]+1)\n",
    "    ordering = ordering['ordering'].to_dict()\n",
    "    \n",
    "    for cat, o in ordering.items():\n",
    "        frame.loc[frame[feature] == cat, feature+'_E'] = o\n",
    "    \n",
    "qual_encoded = []\n",
    "for q in qualitative:  \n",
    "    encode(train, q)\n",
    "    qual_encoded.append(q+'_E')\n",
    "print(qual_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman(frame, features):\n",
    "    spr = pd.DataFrame()\n",
    "    spr['feature'] = features\n",
    "    spr['spearman'] = [frame[f].corr(frame['SalePrice'], 'spearman') for f in features]\n",
    "    spr = spr.sort_values('spearman')\n",
    "    plt.figure(figsize=(6, 0.25*len(features)))\n",
    "    sns.barplot(data=spr, y='feature', x='spearman', orient='h')\n",
    "    \n",
    "features = quantitative + qual_encoded\n",
    "spearman(train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "corr = train[quantitative+['SalePrice']].corr()\n",
    "sns.heatmap(corr)\n",
    "plt.figure(2)\n",
    "corr = train[qual_encoded+['SalePrice']].corr()\n",
    "sns.heatmap(corr)\n",
    "plt.figure(3)\n",
    "corr = pd.DataFrame(np.zeros([len(quantitative)+1, len(qual_encoded)+1]), index=quantitative+['SalePrice'], columns=qual_encoded+['SalePrice'])\n",
    "for q1 in quantitative+['SalePrice']:\n",
    "    for q2 in qual_encoded+['SalePrice']:\n",
    "        corr.loc[q1, q2] = train[q1].corr(train[q2])\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE; PCA+k-means; \n",
    "\n",
    "features = quantitative + qual_encoded\n",
    "model = TSNE(n_components=2, random_state=0, perplexity=50)\n",
    "X = train[features].fillna(0.).values\n",
    "tsne = model.fit_transform(X)\n",
    "\n",
    "std = StandardScaler()\n",
    "s = std.fit_transform(X)\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(s)\n",
    "pc = pca.transform(s)\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(pc)\n",
    "\n",
    "fr = pd.DataFrame({'tsne1': tsne[:,0], 'tsne2': tsne[:, 1], 'cluster': kmeans.labels_})\n",
    "sns.lmplot(data=fr, x='tsne1', y='tsne2', hue='cluster', fit_reg=False)\n",
    "print(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 整理各种检查数据的函数便于使用\n",
    "#print(features_encoded['MSSubClass'].value_counts())\n",
    "\n",
    "#train.info()\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#features_encoded.dtypes\n",
    "\n",
    "# 检查列是否是字符串类型\n",
    "# columns_to_check = ['ExterQual_E', 'BsmtCond_E', 'BsmtFinType1_E', 'BsmtFinType2_E']\n",
    "# str_columns = features_encoded[columns_to_check].select_dtypes(include=['object']).columns\n",
    "\n",
    "# # 打印所有为字符串类型的列\n",
    "# if not str_columns.empty:\n",
    "#     print(f\"以下列是字符串类型: {list(str_columns)}\")\n",
    "# else:\n",
    "#     print(\"没有列是字符串类型\")\n",
    "\n",
    "\n",
    "# # 检查是否存在 object 类型\n",
    "# if (features_encoded.dtypes == 'object').any():\n",
    "#     print(\"仍然有 object 类型的列\")\n",
    "# else:\n",
    "#     print(\"没有 object 类型的列\")\n",
    "\n",
    "#str_columns = features_encoded.select_dtypes(include=['object']).columns\n",
    "#print(str_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查NAN\n",
    "\n",
    "# missing_values = features.isnull().sum()\n",
    "# print(missing_values[missing_values > 0])  # 打印仍然存在缺失值的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inspection\n",
    "# train.shape\n",
    "# train.info()\n",
    "# if \"Id\" in train.columns.tolist():\n",
    "#     dataset_df = train.drop('Id', axis=1)\n",
    "# dataset_df.head(3)\n",
    "\n",
    "# print(dataset_df['SalePrice'].describe())\n",
    "# plt.figure(figsize=(9, 8))\n",
    "# sns.histplot(dataset_df['SalePrice'], color='g', bins=100, kde=True, alpha=0.4)\n",
    "\n",
    "# list(set(dataset_df.dtypes.tolist()))\n",
    "# df_num = dataset_df.select_dtypes(include = ['float64', 'int64'])\n",
    "# df_num.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
